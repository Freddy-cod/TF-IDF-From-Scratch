{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58bfbc4b",
   "metadata": {},
   "source": [
    "## The fit() and transform() methods of my custom implementation of tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aff3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185e407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(corpus):\n",
    "    '''Returns the unique words within a corpus and their index\n",
    "       keys represent the unique words and values indexes'''\n",
    "    unique_words = set()\n",
    "    if isinstance(corpus, (list,)):\n",
    "        for row in corpus: # for each review in the dataset\n",
    "            for word in row.split(\" \"):\n",
    "                word = word.lower() \n",
    "                if len(word) < 2: # dont consider words less than two\n",
    "                    continue\n",
    "                unique_words.add(word) # add unique words only\n",
    "        unique_words = sorted(list(unique_words))\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)} # words and their respective index\n",
    "        return vocab\n",
    "    else:\n",
    "        print(\"Expected a list of sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a76f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(corpus,vocab):\n",
    "    '''Returns the inverse document frequency of a word and the word itself\n",
    "       keys represent the word and the values their respective idf values'''\n",
    "    num_of_docs = len(corpus)\n",
    "    idf_values = {}\n",
    "   \n",
    "    for word in vocab:\n",
    "        num_of_docs_with_term = 0\n",
    "        for doc in corpus:\n",
    "            if word in doc:\n",
    "                num_of_docs_with_term += 1\n",
    "    \n",
    "        idf = 1 + (math.log((1+num_of_docs)/(1 + num_of_docs_with_term)))\n",
    "        \n",
    "        idf_values[word] = idf\n",
    "        \n",
    "    return idf_values\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26150098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(corpus,vocab):\n",
    "    # initialize a matrix\n",
    "    sparse_matrix= csr_matrix((len(corpus), len(vocab)))\n",
    "    \n",
    "    # loop through the corpus and calculate tfidf\n",
    "    for index, doc in enumerate(corpus):\n",
    "        num_of_words_in_doc = Counter(corpus[index].split())\n",
    "        for word in corpus[index].split():\n",
    "            if word in vocab.keys():\n",
    "                num_of_terms_in_doc = len(doc.split())\n",
    "\n",
    "                tf = num_of_words_in_doc[word] / num_of_terms_in_doc\n",
    "\n",
    "                idf_value = idf(corpus,vocab)[word]\n",
    "                tf_idf_value = tf * idf_value\n",
    "  \n",
    "                sparse_matrix[index, vocab[word]] = tf_idf_value\n",
    "    print(normalize(sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67cd06c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "     'this is the first document',\n",
    "     'this document is the second document',\n",
    "     'and this is the third one',\n",
    "     'is this the first document',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e04c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.4697913855799205\n",
      "  (0, 2)\t0.580285823684436\n",
      "  (0, 3)\t0.3840852409148149\n",
      "  (0, 6)\t0.3840852409148149\n",
      "  (0, 8)\t0.3840852409148149\n",
      "  (1, 1)\t0.6876235979836937\n",
      "  (1, 3)\t0.2810886740337529\n",
      "  (1, 5)\t0.5386476208856762\n",
      "  (1, 6)\t0.2810886740337529\n",
      "  (1, 8)\t0.2810886740337529\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (3, 1)\t0.4697913855799205\n",
      "  (3, 2)\t0.580285823684436\n",
      "  (3, 3)\t0.3840852409148149\n",
      "  (3, 6)\t0.3840852409148149\n",
      "  (3, 8)\t0.3840852409148149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "vocab = fit(corpus)\n",
    "transform(corpus,vocab)\n",
    "\n",
    "\n",
    "# Final output of my sparse matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
