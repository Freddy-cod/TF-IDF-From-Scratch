{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368a5413",
   "metadata": {},
   "source": [
    "## Modifying the fit and transform functions so that the vocab will contain only 50 terms with top idf scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07949225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc697a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in corpus =  746\n"
     ]
    }
   ],
   "source": [
    "with open('cleaned_strings', 'rb') as f:\n",
    "    new_corpus = pickle.load(f)\n",
    "    \n",
    "# printing the length of the corpus loaded\n",
    "print(\"Number of documents in corpus = \",len(new_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3ab6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slow moving aimless movie distressed drifting young man', 'not sure lost flat characters audience nearly half walked', 'attempting artiness black white clever camera angles movie disappointed became even ridiculous acting poor plot lines almost non existent', 'little music anything speak', 'best scene movie gerardo trying find song keeps running head']\n"
     ]
    }
   ],
   "source": [
    "print(new_corpus[:5]) # preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f712ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(new_corpus):\n",
    "    '''Returns the unique words within a corpus and their index\n",
    "       keys represent the unique words and values indexes'''\n",
    "    unique_words = set()\n",
    "    if isinstance(new_corpus, (list,)):\n",
    "        for row in new_corpus: # for each review in the dataset\n",
    "            for word in row.split(\" \"):\n",
    "                word = word.lower() \n",
    "                if len(word) < 2: # dont consider words less than two\n",
    "                    continue\n",
    "                unique_words.add(word) # add unique words only\n",
    "        unique_words = sorted(list(unique_words))\n",
    "        vocab = {j:i for i,j in enumerate(unique_words)} # words and their respective index\n",
    "        return vocab\n",
    "    \n",
    "    else:\n",
    "        print(\"Expected a list of sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a05ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(new_corpus,vocab):\n",
    "    '''Returns the inverse document frequency of a word and the word itself\n",
    "       keys represent the word and the values their respective idf values'''\n",
    "    num_of_docs = len(new_corpus)\n",
    "    idf_values = {}\n",
    "   \n",
    "    for word in vocab:\n",
    "        num_of_docs_with_term = 0\n",
    "        for doc in new_corpus:\n",
    "            if word in doc:\n",
    "                num_of_docs_with_term += 1\n",
    "    \n",
    "        idf = 1 + (math.log((1+num_of_docs)/(1 + num_of_docs_with_term)))\n",
    "        \n",
    "        idf_values[word] = idf\n",
    "   \n",
    "    # return the first 50 words with top idf\n",
    "    new_set = {}\n",
    "    for word_idf in sorted(zip(idf_values.values(),idf_values.keys()))[-50:]:\n",
    "        new_set[word_idf[1]] = word_idf[0]\n",
    "    return new_set\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de0e614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'waster': 6.922918004572872,\n",
       " 'wasting': 6.922918004572872,\n",
       " 'wave': 6.922918004572872,\n",
       " 'waylaid': 6.922918004572872,\n",
       " 'wayne': 6.922918004572872,\n",
       " 'weaker': 6.922918004572872,\n",
       " 'weariness': 6.922918004572872,\n",
       " 'weaving': 6.922918004572872,\n",
       " 'website': 6.922918004572872,\n",
       " 'wedding': 6.922918004572872,\n",
       " 'weight': 6.922918004572872,\n",
       " 'welsh': 6.922918004572872,\n",
       " 'went': 6.922918004572872,\n",
       " 'whenever': 6.922918004572872,\n",
       " 'whine': 6.922918004572872,\n",
       " 'whites': 6.922918004572872,\n",
       " 'whoever': 6.922918004572872,\n",
       " 'wide': 6.922918004572872,\n",
       " 'widmark': 6.922918004572872,\n",
       " 'wife': 6.922918004572872,\n",
       " 'wih': 6.922918004572872,\n",
       " 'wild': 6.922918004572872,\n",
       " 'william': 6.922918004572872,\n",
       " 'willie': 6.922918004572872,\n",
       " 'wily': 6.922918004572872,\n",
       " 'within': 6.922918004572872,\n",
       " 'witticisms': 6.922918004572872,\n",
       " 'woa': 6.922918004572872,\n",
       " 'wondered': 6.922918004572872,\n",
       " 'wong': 6.922918004572872,\n",
       " 'wont': 6.922918004572872,\n",
       " 'worked': 6.922918004572872,\n",
       " 'worry': 6.922918004572872,\n",
       " 'worthless': 6.922918004572872,\n",
       " 'worthwhile': 6.922918004572872,\n",
       " 'wouldnt': 6.922918004572872,\n",
       " 'woven': 6.922918004572872,\n",
       " 'wow': 6.922918004572872,\n",
       " 'wrap': 6.922918004572872,\n",
       " 'writers': 6.922918004572872,\n",
       " 'wrote': 6.922918004572872,\n",
       " 'yardley': 6.922918004572872,\n",
       " 'yawn': 6.922918004572872,\n",
       " 'yelps': 6.922918004572872,\n",
       " 'younger': 6.922918004572872,\n",
       " 'youthful': 6.922918004572872,\n",
       " 'youtube': 6.922918004572872,\n",
       " 'yun': 6.922918004572872,\n",
       " 'zillion': 6.922918004572872,\n",
       " 'zombiez': 6.922918004572872}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 50 words with the highest idf value\n",
    "vocab_set = fit(new_corpus)\n",
    "vocabulary = idf(new_corpus,vocab_set)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35409960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(new_corpus,vocab):\n",
    "    # initialize a matrix\n",
    "    sparse_matrix= csr_matrix((len(new_corpus), len(vocab)))\n",
    "    \n",
    "    # assign words to their indexes\n",
    "    vocab_with_index = {}\n",
    "    for idx,uniq_word in enumerate(vocabulary):\n",
    "        vocab_with_index[uniq_word] = idx\n",
    "    \n",
    "    # loop through the corpus and calculate tfidf\n",
    "    for index, doc in enumerate(new_corpus):\n",
    "        \n",
    "        num_of_words_in_doc = Counter(new_corpus[index].split())\n",
    "        for word in new_corpus[index].split():\n",
    "        #  print(new_corpus[index].split())\n",
    "         \n",
    "            if word in vocab.keys():\n",
    "\n",
    "                num_of_terms_in_doc = len(doc.split())\n",
    "\n",
    "                tf = num_of_words_in_doc[word] / num_of_terms_in_doc\n",
    "\n",
    "                idf_value = idf(new_corpus,vocab)[word]\n",
    "                tf_idf_value = tf * idf_value\n",
    "                \n",
    "             \n",
    "                sparse_matrix[index,vocab_with_index[word]] = tf_idf_value\n",
    "                \n",
    "    print(normalize(sparse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cdf149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (19, 16)\t0.5773502691896258\n",
      "  (19, 32)\t0.5773502691896258\n",
      "  (19, 45)\t0.5773502691896258\n",
      "  (55, 5)\t1.0\n",
      "  (68, 19)\t1.0\n",
      "  (70, 9)\t1.0\n",
      "  (80, 14)\t1.0\n",
      "  (109, 49)\t1.0\n",
      "  (134, 4)\t1.0\n",
      "  (135, 6)\t0.408248290463863\n",
      "  (135, 8)\t0.408248290463863\n",
      "  (135, 20)\t0.408248290463863\n",
      "  (135, 26)\t0.408248290463863\n",
      "  (135, 27)\t0.408248290463863\n",
      "  (135, 38)\t0.408248290463863\n",
      "  (148, 3)\t0.5773502691896257\n",
      "  (148, 17)\t0.5773502691896257\n",
      "  (148, 42)\t0.5773502691896257\n",
      "  (155, 39)\t1.0\n",
      "  (191, 24)\t1.0\n",
      "  (222, 43)\t1.0\n",
      "  (251, 37)\t1.0\n",
      "  (270, 47)\t1.0\n",
      "  (321, 48)\t1.0\n",
      "  (326, 18)\t1.0\n",
      "  (337, 15)\t1.0\n",
      "  (340, 35)\t1.0\n",
      "  (341, 23)\t1.0\n",
      "  (350, 22)\t0.7071067811865476\n",
      "  (350, 29)\t0.7071067811865476\n",
      "  (361, 40)\t1.0\n",
      "  (366, 31)\t1.0\n",
      "  (378, 10)\t1.0\n",
      "  (421, 11)\t1.0\n",
      "  (452, 36)\t1.0\n",
      "  (464, 12)\t1.0\n",
      "  (495, 30)\t1.0\n",
      "  (514, 41)\t1.0\n",
      "  (518, 46)\t1.0\n",
      "  (521, 0)\t1.0\n",
      "  (525, 1)\t1.0\n",
      "  (535, 13)\t1.0\n",
      "  (562, 21)\t1.0\n",
      "  (633, 25)\t1.0\n",
      "  (634, 28)\t1.0\n",
      "  (644, 44)\t1.0\n",
      "  (680, 34)\t1.0\n",
      "  (719, 2)\t1.0\n",
      "  (720, 33)\t1.0\n",
      "  (734, 7)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alfre\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_index.py:103: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "vocabulary\n",
    "\n",
    "transform(new_corpus,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aabbbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
